{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjNAmtyUT33o"
      },
      "source": [
        "<h2>Sentence Transformers</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC08IHg2jNe1"
      },
      "source": [
        "**Resources:**\n",
        "\n",
        "*   https://www.sbert.net/index.html\n",
        "*   https://www.sbert.net/docs/pretrained_models.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ9U2MTSQCGe"
      },
      "source": [
        "**Use cases:**\n",
        "\n",
        "\n",
        "\n",
        "*   Sentence Embedding\n",
        "*   Sentence Similarity\n",
        "*   Semantic Search\n",
        "*   Clustering\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fe3mt_jCTL0"
      },
      "source": [
        "**Generate Embeding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QXuwDrEsTl-7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/udayb/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 9.96MB/s]\n",
            "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.77MB/s]\n",
            "Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 52.9MB/s]\n",
            "Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<00:00, 4.88MB/s]\n",
            "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 484kB/s]\n",
            "Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 277kB/s]\n",
            "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:10<00:00, 8.84MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 515kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 1.16MB/s]\n",
            "Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 504kB/s]\n",
            "Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 1.37MB/s]\n",
            "Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 60.1MB/s]\n",
            "Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.14MB/s]\n",
            "Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<00:00, 4.27MB/s]\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer,util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "03fm2wdZejPc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: This framework generates embeddings for each input sentence\n",
            "Embedding: [-1.37173245e-02 -4.28515784e-02 -1.56286154e-02  1.40537424e-02\n",
            "  3.95537950e-02  1.21796258e-01  2.94333603e-02 -3.17524038e-02\n",
            "  3.54959220e-02 -7.93140531e-02  1.75878778e-02 -4.04369682e-02\n",
            "  4.97259684e-02  2.54913121e-02 -7.18700141e-02  8.14968273e-02\n",
            "  1.47072074e-03  4.79627810e-02 -4.50336188e-02 -9.92174670e-02\n",
            " -2.81769913e-02  6.45045862e-02  4.44670841e-02 -4.76217493e-02\n",
            " -3.52952518e-02  4.38671485e-02 -5.28566614e-02  4.33013309e-04\n",
            "  1.01921499e-01  1.64072365e-02  3.26996930e-02 -3.45987044e-02\n",
            "  1.21339653e-02  7.94871002e-02  4.58347425e-03  1.57778990e-02\n",
            " -9.68204997e-03  2.87626125e-02 -5.05806692e-02 -1.55794052e-02\n",
            " -2.87907068e-02 -9.62282438e-03  3.15556005e-02  2.27349456e-02\n",
            "  8.71449709e-02 -3.85027714e-02 -8.84718746e-02 -8.75497144e-03\n",
            " -2.12343540e-02  2.08924171e-02 -9.02078003e-02 -5.25733083e-02\n",
            " -1.05638858e-02  2.88311057e-02 -1.61455423e-02  6.17839489e-03\n",
            " -1.23234401e-02 -1.07337423e-02  2.83354037e-02 -5.28568178e-02\n",
            " -3.58618274e-02 -5.97989261e-02 -1.09055033e-02  2.91566905e-02\n",
            "  7.97979459e-02 -3.27863207e-04  6.83500618e-03  1.32718422e-02\n",
            " -4.24620062e-02  1.87656712e-02 -9.89234895e-02  2.09049527e-02\n",
            " -8.69605690e-02 -1.50152287e-02 -4.86202426e-02  8.04414973e-02\n",
            " -3.67697142e-03 -6.65043965e-02  1.14556789e-01 -3.04228980e-02\n",
            "  2.96631865e-02 -2.80694570e-02  4.64990139e-02 -2.25513969e-02\n",
            "  8.54223743e-02  3.15446481e-02  7.34541938e-02 -2.21861396e-02\n",
            " -5.29679060e-02  1.27130421e-02 -5.27339466e-02 -1.06188737e-01\n",
            "  7.04731867e-02  2.76736505e-02 -8.05531517e-02  2.39649378e-02\n",
            " -2.65125465e-02 -2.17330456e-02  4.35275398e-02  4.84712012e-02\n",
            " -2.37067677e-02  2.85768546e-02  1.11846179e-01 -6.34935126e-02\n",
            " -1.58318114e-02 -2.26169489e-02 -1.31028201e-02 -1.62071723e-03\n",
            " -3.60928997e-02 -9.78297740e-02 -4.67729159e-02  1.76271815e-02\n",
            " -3.97492200e-02 -1.76402275e-04  3.39628123e-02 -2.09633559e-02\n",
            "  6.33659633e-03 -2.59410385e-02  8.10411349e-02  6.14393465e-02\n",
            " -5.44603681e-03  6.48275390e-02 -1.16844043e-01  2.36860868e-02\n",
            " -1.32058281e-02 -1.12476513e-01  1.90049578e-02 -1.74662114e-34\n",
            "  5.58949038e-02  1.94245260e-02  4.65438850e-02  5.18645793e-02\n",
            "  3.89390327e-02  3.40541080e-02 -4.32114713e-02  7.90637136e-02\n",
            " -9.79529992e-02 -1.27441119e-02 -2.91871093e-02  1.02052707e-02\n",
            "  1.88116264e-02  1.08942553e-01  6.63465038e-02 -5.35295308e-02\n",
            " -3.29228789e-02  4.69827540e-02  2.28882786e-02  2.74114702e-02\n",
            " -2.91982796e-02  3.12706493e-02 -2.22851038e-02 -1.02282159e-01\n",
            " -2.79117059e-02  1.13792634e-02  9.06309038e-02 -4.75414619e-02\n",
            " -1.00719005e-01 -1.23231970e-02 -7.96928480e-02 -1.44636864e-02\n",
            " -7.76400939e-02 -7.66919414e-03  9.73952282e-03  2.24205013e-02\n",
            "  7.77268261e-02 -3.17156501e-03  2.11538430e-02 -3.30393910e-02\n",
            "  9.55246575e-03 -3.73011716e-02  2.61360742e-02 -9.79085919e-03\n",
            " -6.31505474e-02  5.77431265e-03 -3.80031504e-02  1.29683940e-02\n",
            " -1.82499420e-02 -1.56283490e-02 -1.23360194e-03  5.55578880e-02\n",
            "  1.13107206e-04 -5.61256558e-02  7.40164965e-02  1.84452031e-02\n",
            " -2.66368613e-02  1.31951449e-02  7.50086755e-02 -2.46797651e-02\n",
            " -3.24006900e-02 -1.57674532e-02 -8.03518575e-03 -5.61321853e-03\n",
            "  1.05687603e-02  3.26160924e-03 -3.91990356e-02 -9.38677713e-02\n",
            "  1.14227146e-01  6.57304749e-02 -4.72633615e-02  1.45087773e-02\n",
            " -3.54489982e-02 -3.37761268e-02 -5.15505634e-02 -3.81002016e-03\n",
            " -5.15036099e-02 -5.93429282e-02 -1.69410708e-03  7.42107555e-02\n",
            " -4.20092046e-02 -7.19975084e-02  3.17250155e-02 -1.66303627e-02\n",
            "  3.96985607e-03 -6.52750582e-02  2.77390853e-02 -7.51649216e-02\n",
            "  2.27455515e-02 -3.91368903e-02  1.54315680e-02 -5.54908253e-02\n",
            "  1.23318890e-02 -2.59520859e-02  6.66423738e-02 -6.91257305e-34\n",
            "  3.31628919e-02  8.47929642e-02 -6.65584505e-02  3.33541781e-02\n",
            "  4.71607875e-03  1.35362083e-02 -5.38694002e-02  9.20694172e-02\n",
            " -2.96876933e-02  3.16219591e-02 -2.37497892e-02  1.98771153e-02\n",
            "  1.03446200e-01 -9.06947181e-02  6.30626315e-03  1.42886406e-02\n",
            "  1.19293937e-02  6.43725554e-03  4.20105271e-02  1.25344153e-02\n",
            "  3.93018983e-02  5.35691231e-02 -4.30749618e-02  6.10432960e-02\n",
            " -5.39587600e-05  6.91682994e-02  1.05520394e-02  1.22111719e-02\n",
            " -7.23185316e-02  2.50469558e-02 -5.18371239e-02 -4.36562337e-02\n",
            " -6.71818405e-02  1.34828687e-02 -7.25888833e-02  7.04163313e-03\n",
            "  6.58938661e-02  1.08994385e-02 -2.60008895e-03  5.49969524e-02\n",
            "  5.06966710e-02  3.27948779e-02 -6.68832660e-02  6.45557493e-02\n",
            " -2.52076369e-02 -2.92571764e-02 -1.16696708e-01  3.24064605e-02\n",
            "  5.85858300e-02 -3.51757072e-02 -7.15240240e-02  2.24936437e-02\n",
            " -1.00786746e-01 -4.74544577e-02 -7.61962757e-02 -5.87166101e-02\n",
            "  4.21139188e-02 -7.47213885e-02  1.98467616e-02 -3.36500281e-03\n",
            " -5.29735833e-02  2.74729636e-02  3.45736556e-02 -6.11846149e-02\n",
            "  1.06364839e-01 -9.64119956e-02 -4.55945320e-02  1.51489154e-02\n",
            " -5.13528194e-03 -6.64447695e-02  4.31721471e-02 -1.10405888e-02\n",
            " -9.80253890e-03  7.53782839e-02 -1.49571253e-02 -4.80208322e-02\n",
            "  5.80726638e-02 -2.43897233e-02 -2.23137848e-02 -4.36992757e-02\n",
            "  5.12054190e-02 -3.28625850e-02  1.08763315e-01  6.08926155e-02\n",
            "  3.30788083e-03  5.53820580e-02  8.43200982e-02  1.27086854e-02\n",
            "  3.84465493e-02  6.52325600e-02 -2.94684116e-02  5.08005507e-02\n",
            " -2.09347885e-02  1.46135673e-01  2.25561466e-02 -1.77227744e-08\n",
            " -5.02672531e-02 -2.79133266e-04 -1.00328572e-01  2.42811292e-02\n",
            " -7.54042864e-02 -3.79139669e-02  3.96050103e-02  3.10080051e-02\n",
            " -9.05705523e-03 -6.50412068e-02  4.05453108e-02  4.83389795e-02\n",
            " -4.56962287e-02  4.76003578e-03  2.64364877e-03  9.35614333e-02\n",
            " -4.02599573e-02  3.27402130e-02  1.18298251e-02  5.54345176e-02\n",
            "  1.48052290e-01  7.21189678e-02  2.76974373e-04  1.68650858e-02\n",
            "  8.34881142e-03 -8.76159873e-03 -1.33649465e-02  6.14236966e-02\n",
            "  1.57167371e-02  6.94960430e-02  1.08621381e-02  6.08018562e-02\n",
            " -5.33420965e-02 -3.47924568e-02 -3.36271934e-02  6.93906546e-02\n",
            "  1.22987861e-02 -1.45237416e-01 -2.06971401e-03 -4.61132862e-02\n",
            "  3.72744724e-03 -5.59349125e-03 -1.00659780e-01 -4.45953086e-02\n",
            "  5.40921465e-02  4.98893298e-03  1.49535313e-02 -8.26059431e-02\n",
            "  6.26630485e-02 -5.01901889e-03 -4.81857248e-02 -3.53991166e-02\n",
            "  9.03387275e-03 -2.42337715e-02  5.66267222e-02  2.51528770e-02\n",
            " -1.70709342e-02 -1.24780377e-02  3.19517963e-02  1.38421003e-02\n",
            " -1.55815240e-02  1.00178249e-01  1.23657271e-01 -4.22967263e-02]\n",
            "\n",
            "Sentence: Sentences are passed as a list of string.\n",
            "Embedding: [ 5.64524941e-02  5.50023727e-02  3.13795209e-02  3.39484625e-02\n",
            " -3.54247019e-02  8.34667534e-02  9.88800526e-02  7.27541605e-03\n",
            " -6.68658828e-03 -7.65812397e-03  7.93738067e-02  7.39726413e-04\n",
            "  1.49291819e-02 -1.51046477e-02  3.67674343e-02  4.78742756e-02\n",
            " -4.81969528e-02 -3.76052000e-02 -4.60278131e-02 -8.89816210e-02\n",
            "  1.20228179e-01  1.30663306e-01 -3.73936184e-02  2.47853063e-03\n",
            "  2.55824346e-03  7.25814849e-02 -6.80436194e-02 -5.24696335e-02\n",
            "  4.90234531e-02  2.99563110e-02 -5.84429391e-02 -2.02262662e-02\n",
            "  2.08821893e-02  9.76691842e-02  3.52390632e-02  3.91141847e-02\n",
            "  1.05668493e-02  1.56236754e-03 -1.30822724e-02  8.52904748e-03\n",
            " -4.84092301e-03 -2.03766320e-02 -2.71801446e-02  2.83308141e-02\n",
            "  3.66017409e-02  2.51276232e-02 -9.90861952e-02  1.15626371e-02\n",
            " -3.60380635e-02 -7.23784417e-02 -1.12670146e-01  1.12942159e-02\n",
            " -3.86398025e-02  4.67386283e-02 -2.88460646e-02  2.26704348e-02\n",
            " -8.52405000e-03  3.32815461e-02 -1.06581370e-03 -7.09745288e-02\n",
            " -6.31170124e-02 -5.72186485e-02 -6.16026297e-02  5.47146611e-02\n",
            "  1.18317883e-02 -4.66261208e-02  2.56959591e-02 -7.07414467e-03\n",
            " -5.73842786e-02  4.12839837e-02 -5.91503456e-02  5.89021929e-02\n",
            " -4.41697240e-02  4.65081632e-02 -3.15814950e-02  5.58312312e-02\n",
            "  5.54578714e-02 -5.96533343e-02  4.06407081e-02  4.83763684e-03\n",
            " -4.96768169e-02 -1.00944363e-01  3.40078510e-02  4.13269596e-03\n",
            " -2.93526938e-03  2.11838074e-02 -3.73962410e-02 -2.79067568e-02\n",
            " -4.61767651e-02  5.26138544e-02 -2.79734954e-02 -1.62379280e-01\n",
            "  6.61042631e-02  1.72274876e-02 -5.45105292e-03  4.74473983e-02\n",
            " -3.82237323e-02 -3.96896526e-02  1.34544726e-02  4.49654087e-02\n",
            "  4.53673070e-03  2.82978769e-02  8.36632699e-02 -1.00857839e-02\n",
            " -1.19354002e-01 -3.84625047e-02  4.82858419e-02 -9.46084410e-02\n",
            "  1.91854481e-02 -9.96518582e-02 -6.30596876e-02  3.02696303e-02\n",
            "  1.17402440e-02 -4.78372425e-02 -6.20269775e-03 -3.32850814e-02\n",
            " -4.04391438e-03  1.28307343e-02  4.05254588e-02  7.56476969e-02\n",
            "  2.92435065e-02  2.84270439e-02 -2.78938077e-02  1.66858211e-02\n",
            " -2.47961152e-02 -6.83651492e-02  2.89968736e-02 -5.39867858e-33\n",
            " -2.69018603e-03 -2.65069380e-02 -6.47934619e-04 -8.46198853e-03\n",
            " -7.35154971e-02  4.94083948e-03 -5.97841851e-02  1.03438161e-02\n",
            "  2.12905789e-03 -2.88215955e-03 -3.17076407e-02 -9.42364633e-02\n",
            "  3.03019825e-02  7.00227693e-02  4.50685024e-02  3.69439386e-02\n",
            "  1.13593535e-02  3.53027135e-02  5.50446892e-03  1.34415156e-03\n",
            "  3.46124964e-03  7.75048062e-02  5.45112491e-02 -7.92055875e-02\n",
            " -9.31697339e-02 -4.03398722e-02  3.10668889e-02 -3.83081585e-02\n",
            " -5.89442514e-02  1.93332173e-02 -2.67160013e-02 -7.91938528e-02\n",
            "  1.04184845e-04  7.70621002e-02  4.16604020e-02  8.90932605e-02\n",
            "  3.56843136e-02 -1.09152747e-02  3.71498652e-02 -2.07070783e-02\n",
            " -2.46100631e-02 -2.05025058e-02  2.62201577e-02  3.43590379e-02\n",
            "  4.39251140e-02 -8.20520334e-03 -8.40710327e-02  4.24171016e-02\n",
            "  4.87498529e-02  5.95385060e-02  2.87747774e-02  3.37638445e-02\n",
            " -4.07442674e-02 -1.66373164e-03  7.91927502e-02  3.41088399e-02\n",
            " -5.72838995e-04  1.87749453e-02 -1.36964647e-02  7.38333240e-02\n",
            "  5.74454141e-04  8.33505392e-02  5.60810827e-02 -1.13710798e-02\n",
            "  4.42611389e-02  2.69582104e-02 -4.80536632e-02 -3.15087475e-02\n",
            "  7.75226578e-02  1.81773454e-02 -8.83005187e-02 -7.85513222e-03\n",
            " -6.22243434e-02  7.19372705e-02 -2.33474914e-02  6.52477192e-03\n",
            " -9.49526764e-03 -9.88312736e-02  4.01306599e-02  3.07396557e-02\n",
            " -2.21606847e-02 -9.45911184e-02  1.02367811e-02  1.02187760e-01\n",
            " -4.12960388e-02 -3.15777585e-02  4.74752188e-02 -1.10209800e-01\n",
            "  1.69614572e-02 -3.71709317e-02 -1.03261890e-02 -4.72538695e-02\n",
            " -1.20214475e-02 -1.93255469e-02  5.79292476e-02  4.23865401e-34\n",
            "  3.92013267e-02  8.41361359e-02 -1.02946743e-01  6.92259967e-02\n",
            "  1.68821216e-02 -3.26760337e-02  9.65957157e-03  1.80899501e-02\n",
            "  2.17940081e-02  1.63189303e-02 -9.69292596e-02  3.74852004e-03\n",
            " -2.38457043e-02 -3.44055817e-02  7.11962804e-02  9.21912026e-04\n",
            " -6.23863097e-03  3.23754698e-02 -8.90360097e-04  5.01905195e-03\n",
            " -4.24538292e-02  9.89083722e-02 -4.60320786e-02  4.69704643e-02\n",
            " -1.75283961e-02 -7.02516083e-03  1.32743781e-02 -5.30152433e-02\n",
            "  2.66404753e-03  1.45819252e-02  7.43346289e-03 -3.07131857e-02\n",
            " -2.09416877e-02  8.24110135e-02 -5.15893735e-02 -2.71178186e-02\n",
            "  1.17583051e-01  7.72501901e-03 -1.89523306e-02  3.94559503e-02\n",
            "  7.17360452e-02  2.59117242e-02  2.75191925e-02  9.50540882e-03\n",
            " -3.02355383e-02 -4.07944992e-02 -1.04028471e-01 -7.97417015e-03\n",
            " -3.64453322e-03  3.29716206e-02 -2.35954430e-02 -7.50516541e-03\n",
            " -5.82234003e-02 -3.17906514e-02 -4.18048836e-02  2.17453502e-02\n",
            " -6.67292625e-02 -4.89104465e-02  4.58515901e-03 -2.66045760e-02\n",
            " -1.12597004e-01  5.11167273e-02  5.48534282e-02 -6.69857934e-02\n",
            "  1.26766324e-01 -8.59487429e-02 -5.94231859e-02 -2.92187394e-03\n",
            " -1.14875520e-02 -1.26025811e-01 -3.48280673e-03 -9.12002251e-02\n",
            " -1.22933112e-01  1.33777261e-02 -4.75775525e-02 -6.57933429e-02\n",
            " -3.39409672e-02 -3.07108145e-02 -5.22034243e-02 -2.35464051e-02\n",
            "  5.90034984e-02 -3.85758094e-02  3.19700651e-02  4.05118391e-02\n",
            "  1.67077947e-02 -3.58281657e-02  1.45688169e-02  3.20137590e-02\n",
            " -1.34843383e-02  6.07819706e-02 -8.31397530e-03 -1.08105876e-02\n",
            "  4.69410457e-02  7.66133741e-02 -4.23400216e-02 -2.11963300e-08\n",
            " -7.25292936e-02 -4.20227833e-02 -6.12374730e-02  5.24666868e-02\n",
            " -1.42364167e-02  1.18487114e-02 -1.40789226e-02 -3.67530324e-02\n",
            " -4.44977544e-02 -1.15141189e-02  5.23317307e-02  2.96651982e-02\n",
            " -4.62780371e-02 -3.70892137e-02  1.89129561e-02  2.04307158e-02\n",
            " -2.24005971e-02 -1.48563227e-02 -1.79504156e-02  4.20007966e-02\n",
            "  1.40942335e-02 -2.83492859e-02 -1.16863012e-01  1.48956589e-02\n",
            " -7.30590196e-04  5.66028543e-02 -2.68739834e-02  1.09106742e-01\n",
            "  2.94565270e-03  1.19267911e-01  1.14212438e-01  8.92974213e-02\n",
            " -1.70254856e-02 -4.99054007e-02 -2.11930946e-02  3.18421349e-02\n",
            "  7.03435689e-02 -1.02929391e-01  8.23816508e-02  2.81968247e-02\n",
            "  3.21146064e-02  3.79107967e-02 -1.09553069e-01  8.19620863e-02\n",
            "  8.73216838e-02 -5.73563911e-02 -2.01709270e-02 -5.69444187e-02\n",
            " -1.30338455e-02 -5.55684343e-02 -1.32966535e-02  8.64013005e-03\n",
            "  5.30012436e-02 -4.06846814e-02  2.71709394e-02 -2.55947700e-03\n",
            "  3.05775106e-02 -4.61865515e-02  4.68029827e-03 -3.64946984e-02\n",
            "  6.80802688e-02  6.65087402e-02  8.49151686e-02 -3.32849286e-02]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences = ['This framework generates embeddings for each input sentence',\n",
        "    'Sentences are passed as a list of string.']\n",
        "\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "\n",
        "for sentence, embedding in zip(sentences, embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", embedding)\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDc8_VCrCQGt"
      },
      "source": [
        "**Cosine-Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGz3bDLhewrZ",
        "outputId": "a14d7c3c-638a-4975-e70c-370d8a61ca03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine-Similarity: tensor([[0.5398]])\n"
          ]
        }
      ],
      "source": [
        "emb1 = model.encode(\"I am eating Apple\")\n",
        "emb2 = model.encode(\"I like fruits\")\n",
        "cos_sim = util.cos_sim(emb1, emb2)\n",
        "print(\"Cosine-Similarity:\", cos_sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml5sIVHOCY6u"
      },
      "source": [
        "**Compute cosine similarity between all pairs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lyr6Tjge9UY",
        "outputId": "01b57e4d-0c3d-435e-8b4f-25eda073c88e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  0.7553, -0.1050,  0.2474, -0.0704, -0.0333,  0.1707,  0.0476,\n",
              "          0.0630],\n",
              "        [ 0.7553,  1.0000, -0.0610,  0.1442, -0.0809, -0.0216,  0.1157,  0.0362,\n",
              "          0.0216],\n",
              "        [-0.1050, -0.0610,  1.0000, -0.1088,  0.0217, -0.0413, -0.0928,  0.0231,\n",
              "          0.0247],\n",
              "        [ 0.2474,  0.1442, -0.1088,  1.0000, -0.0348,  0.0362,  0.7369,  0.0821,\n",
              "          0.1389],\n",
              "        [-0.0704, -0.0809,  0.0217, -0.0348,  1.0000, -0.1654, -0.0592,  0.1961,\n",
              "          0.2564],\n",
              "        [-0.0333, -0.0216, -0.0413,  0.0362, -0.1654,  1.0000,  0.0769, -0.0380,\n",
              "         -0.0895],\n",
              "        [ 0.1707,  0.1157, -0.0928,  0.7369, -0.0592,  0.0769,  1.0000,  0.0495,\n",
              "          0.1191],\n",
              "        [ 0.0476,  0.0362,  0.0231,  0.0821,  0.1961, -0.0380,  0.0495,  1.0000,\n",
              "          0.6433],\n",
              "        [ 0.0630,  0.0216,  0.0247,  0.1389,  0.2564, -0.0895,  0.1191,  0.6433,\n",
              "          1.0000]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute cosine similarity between all pairs\n",
        "\n",
        "sentences = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'A man is riding a horse.',\n",
        "          'A woman is playing violin.',\n",
        "          'Two men pushed carts through the woods.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'Someone in a gorilla costume is playing a set of drums.'\n",
        "          ]\n",
        "\n",
        "#Encode all sentences\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "#Compute cosine similarity between all pairs\n",
        "cos_sim = util.cos_sim(embeddings, embeddings)\n",
        "\n",
        "cos_sim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06H7O06b91_q",
        "outputId": "ecf163db-0c42-4ebe-9a3f-9f5b6f900272"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(tensor(0.7553), 0, 1),\n",
              " (tensor(-0.1050), 0, 2),\n",
              " (tensor(0.2474), 0, 3),\n",
              " (tensor(-0.0704), 0, 4),\n",
              " (tensor(-0.0333), 0, 5),\n",
              " (tensor(0.1707), 0, 6),\n",
              " (tensor(0.0476), 0, 7),\n",
              " (tensor(0.0630), 0, 8),\n",
              " (tensor(-0.0610), 1, 2),\n",
              " (tensor(0.1442), 1, 3),\n",
              " (tensor(-0.0809), 1, 4),\n",
              " (tensor(-0.0216), 1, 5),\n",
              " (tensor(0.1157), 1, 6),\n",
              " (tensor(0.0362), 1, 7),\n",
              " (tensor(0.0216), 1, 8),\n",
              " (tensor(-0.1088), 2, 3),\n",
              " (tensor(0.0217), 2, 4),\n",
              " (tensor(-0.0413), 2, 5),\n",
              " (tensor(-0.0928), 2, 6),\n",
              " (tensor(0.0231), 2, 7),\n",
              " (tensor(0.0247), 2, 8),\n",
              " (tensor(-0.0348), 3, 4),\n",
              " (tensor(0.0362), 3, 5),\n",
              " (tensor(0.7369), 3, 6),\n",
              " (tensor(0.0821), 3, 7),\n",
              " (tensor(0.1389), 3, 8),\n",
              " (tensor(-0.1654), 4, 5),\n",
              " (tensor(-0.0592), 4, 6),\n",
              " (tensor(0.1961), 4, 7),\n",
              " (tensor(0.2564), 4, 8),\n",
              " (tensor(0.0769), 5, 6),\n",
              " (tensor(-0.0380), 5, 7),\n",
              " (tensor(-0.0895), 5, 8),\n",
              " (tensor(0.0495), 6, 7),\n",
              " (tensor(0.1191), 6, 8),\n",
              " (tensor(0.6433), 7, 8)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Add all pairs to a list with their cosine similarity score\n",
        "all_sentence_combinations = []\n",
        "for i in range(len(cos_sim)-1):\n",
        "    for j in range(i+1, len(cos_sim)):\n",
        "        all_sentence_combinations.append((cos_sim[i][j], i, j))\n",
        "all_sentence_combinations        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhggYpNbfK4J",
        "outputId": "b4d486f0-4435-4513-8b01-f99f59946370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-5 most similar pairs:\n",
            "A man is eating food. \t A man is eating a piece of bread. \t 0.7553\n",
            "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.7369\n",
            "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6433\n",
            "A woman is playing violin. \t Someone in a gorilla costume is playing a set of drums. \t 0.2564\n",
            "A man is eating food. \t A man is riding a horse. \t 0.2474\n"
          ]
        }
      ],
      "source": [
        "#Sort list by the highest cosine similarity score\n",
        "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "print(\"Top-5 most similar pairs:\")\n",
        "for score, i, j in all_sentence_combinations[0:5]:\n",
        "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0-VolFWK-Rq"
      },
      "source": [
        "**Semantic search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpX-L96mTthR",
        "outputId": "e4ff82e3-aac0-4853-df35-17df034ffcaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('clips/mfaq')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1gio-Pci9RF",
        "outputId": "5c45c533-ade1-469c-8d16-75248660302a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[{'corpus_id': 0, 'score': 0.5646325945854187}, {'corpus_id': 2, 'score': 0.5142340660095215}, {'corpus_id': 1, 'score': 0.4730038046836853}]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "question = \"<Q>How many models can I host on HuggingFace?\"\n",
        "answer_1 = \"<A>All plans come with unlimited private models and datasets.\"\n",
        "answer_2 = \"<A>AutoNLP is an automatic way to train and deploy state-of-the-art NLP models, seamlessly integrated with the Hugging Face ecosystem.\"\n",
        "answer_3 = \"<A>Based on how much training data and model variants are created, we send you a compute cost and payment link - as low as $10 per job.\"\n",
        "\n",
        "query_embedding = model.encode(question)\n",
        "corpus_embeddings = model.encode([answer_1, answer_2, answer_3])\n",
        "\n",
        "print(util.semantic_search(query_embedding, corpus_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FG1WXOudgYq"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qa18QF-ddMa",
        "outputId": "440e262a-1672-4f9b-e85b-c98bd1f96344"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'answer': 'unlimited', 'end': 29, 'score': 0.701717734336853, 'start': 20}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_model = pipeline(\"question-answering\")\n",
        "question = \"How many models can I host on HuggingFace?\"\n",
        "context = \"All plans come with unlimited private models and datasets.\"\n",
        "qa_model(question = question, context = context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J6IY-4oC4hF"
      },
      "outputs": [],
      "source": [
        "print(util.semantic_search(query_embedding, corpus_embeddings))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9tF0hu6K0TD"
      },
      "source": [
        "**Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC9xCE63G0UF"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Corpus with example sentences\n",
        "corpus = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'Horse is eating grass.',\n",
        "          'A man is eating pasta.',\n",
        "          'A Woman is eating Biryani.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'The baby is carried by the woman',\n",
        "          'A man is riding a horse.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'Someone in a gorilla costume is playing a set of drums.',\n",
        "          'A cheetah is running behind its prey.',\n",
        "          'A cheetah chases prey on across a field.',\n",
        "          'The cheetah is chasing a man who is riding the horse.',\n",
        "          'man and women with their baby are watching cheetah in zoo'\n",
        "          ]\n",
        "corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "# Normalize the embeddings to unit length\n",
        "corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri3xLpcXerJW"
      },
      "outputs": [],
      "source": [
        "corpus_embeddings[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-pCHO7EkDKj",
        "outputId": "9728213e-3be7-4735-b468-9708aa55dcb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 3 1 1 0 0 3 3 2 2 3 3 3 0]\n"
          ]
        }
      ],
      "source": [
        "# source: https://stackoverflow.com/questions/55619176/how-to-cluster-similar-sentences-using-bert\n",
        "\n",
        "clustering_model = KMeans(n_clusters=4)\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "print(cluster_assignment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih-1L7bJJq0k",
        "outputId": "d0bdf4f9-eae8-40a8-d98b-5458b1d26a36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: ['The girl is carrying a baby.',\n",
              "  'The baby is carried by the woman',\n",
              "  'A monkey is playing drums.',\n",
              "  'Someone in a gorilla costume is playing a set of drums.',\n",
              "  'man and women with their baby are watching cheetah in zoo'],\n",
              " 1: ['Horse is eating grass.',\n",
              "  'A man is riding a horse.',\n",
              "  'A man is riding a white horse on an enclosed ground.',\n",
              "  'A cheetah is running behind its prey.',\n",
              "  'A cheetah chases prey on across a field.',\n",
              "  'The cheetah is chasing a man who is riding the horse.'],\n",
              " 2: ['A man is eating food.',\n",
              "  'A man is eating a piece of bread.',\n",
              "  'A man is eating pasta.',\n",
              "  'A Woman is eating Biryani.']}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clustered_sentences = {}\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    if cluster_id not in clustered_sentences:\n",
        "        clustered_sentences[cluster_id] = []\n",
        "\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "clustered_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2eINiS3Sivc",
        "outputId": "90bd9c78-4a64-4ade-a824-225f199c454e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: ['The girl is carrying a baby.',\n",
              "  'The baby is carried by the woman',\n",
              "  'man and women with their baby are watching cheetah in zoo'],\n",
              " 1: ['A man is eating food.',\n",
              "  'A man is eating a piece of bread.',\n",
              "  'A man is eating pasta.',\n",
              "  'A Woman is eating Biryani.'],\n",
              " 2: ['A monkey is playing drums.',\n",
              "  'Someone in a gorilla costume is playing a set of drums.'],\n",
              " 3: ['Horse is eating grass.',\n",
              "  'A man is riding a horse.',\n",
              "  'A man is riding a white horse on an enclosed ground.',\n",
              "  'A cheetah is running behind its prey.',\n",
              "  'A cheetah chases prey on across a field.',\n",
              "  'The cheetah is chasing a man who is riding the horse.']}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clustered_sentences = {}\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    if cluster_id not in clustered_sentences:\n",
        "        clustered_sentences[cluster_id] = []\n",
        "\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "clustered_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5GW-zqcfsPl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Youtube: Course Sentence Transformers.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
